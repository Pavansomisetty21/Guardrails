{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7fc91a-c093-4159-9c71-dc9f9268f965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llm_guard\n",
      "  Downloading llm_guard-0.3.15-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting bc-detect-secrets==1.5.15 (from llm_guard)\n",
      "  Downloading bc_detect_secrets-1.5.15-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting faker<28,>=26.0.0 (from llm_guard)\n",
      "  Downloading Faker-27.4.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting fuzzysearch<0.9,>=0.7 (from llm_guard)\n",
      "  Downloading fuzzysearch-0.7.3.tar.gz (112 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting json-repair<0.29,>=0.25.2 (from llm_guard)\n",
      "  Downloading json_repair-0.28.4-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: nltk<4,>=3.9.1 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from llm_guard) (3.9.1)\n",
      "Collecting presidio-analyzer==2.2.354 (from llm_guard)\n",
      "  Downloading presidio_analyzer-2.2.354-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting presidio-anonymizer==2.2.354 (from llm_guard)\n",
      "  Downloading presidio_anonymizer-2.2.354-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting regex==2024.7.24 (from llm_guard)\n",
      "  Downloading regex-2024.7.24-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tiktoken<0.8,>=0.5 (from llm_guard)\n",
      "  Downloading tiktoken-0.7.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: torch>=2.4.0 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from llm_guard) (2.5.1)\n",
      "Requirement already satisfied: transformers>=4.43.4 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from llm_guard) (4.48.1)\n",
      "Collecting structlog>=24 (from llm_guard)\n",
      "  Downloading structlog-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting oldest-supported-numpy (from llm_guard)\n",
      "  Downloading oldest_supported_numpy-2023.12.21-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from bc-detect-secrets==1.5.15->llm_guard) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from bc-detect-secrets==1.5.15->llm_guard) (2.32.3)\n",
      "Collecting unidiff (from bc-detect-secrets==1.5.15->llm_guard)\n",
      "  Downloading unidiff-0.7.5-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting spacy<4.0.0,>=3.4.4 (from presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading spacy-3.8.4-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting tldextract (from presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting phonenumbers<9.0.0,>=8.12 (from presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading phonenumbers-8.13.54-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pycryptodome>=3.10.1 (from presidio-anonymizer==2.2.354->llm_guard)\n",
      "  Downloading pycryptodome-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from faker<28,>=26.0.0->llm_guard) (2.9.0.post0)\n",
      "Requirement already satisfied: attrs>=19.3 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from fuzzysearch<0.9,>=0.7->llm_guard) (24.3.0)\n",
      "Requirement already satisfied: click in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from nltk<4,>=3.9.1->llm_guard) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from nltk<4,>=3.9.1->llm_guard) (1.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from nltk<4,>=3.9.1->llm_guard) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from torch>=2.4.0->llm_guard) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from torch>=2.4.0->llm_guard) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from torch>=2.4.0->llm_guard) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from torch>=2.4.0->llm_guard) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from torch>=2.4.0->llm_guard) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from torch>=2.4.0->llm_guard) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from torch>=2.4.0->llm_guard) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from sympy==1.13.1->torch>=2.4.0->llm_guard) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from transformers>=4.43.4->llm_guard) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from transformers>=4.43.4->llm_guard) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from transformers>=4.43.4->llm_guard) (24.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from transformers>=4.43.4->llm_guard) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from transformers>=4.43.4->llm_guard) (0.5.2)\n",
      "Collecting numpy>=1.17 (from transformers>=4.43.4->llm_guard)\n",
      "  Downloading numpy-1.26.2-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from python-dateutil>=2.4->faker<28,>=26.0.0->llm_guard) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from requests->bc-detect-secrets==1.5.15->llm_guard) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from requests->bc-detect-secrets==1.5.15->llm_guard) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from requests->bc-detect-secrets==1.5.15->llm_guard) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from requests->bc-detect-secrets==1.5.15->llm_guard) (2024.12.14)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading thinc-8.3.4-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard) (2.10.5)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from tqdm->nltk<4,>=3.9.1->llm_guard) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from jinja2->torch>=2.4.0->llm_guard) (3.0.2)\n",
      "Collecting requests-file>=1.4 (from tldextract->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard) (2.27.2)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading blis-1.2.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard) (2.19.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\pavansomisetty\\anaconda3\\envs\\chatai\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard) (1.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio-analyzer==2.2.354->llm_guard)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading llm_guard-0.3.15-py3-none-any.whl (138 kB)\n",
      "Downloading bc_detect_secrets-1.5.15-py3-none-any.whl (119 kB)\n",
      "Downloading presidio_analyzer-2.2.354-py3-none-any.whl (92 kB)\n",
      "Downloading presidio_anonymizer-2.2.354-py3-none-any.whl (31 kB)\n",
      "Downloading regex-2024.7.24-cp312-cp312-win_amd64.whl (269 kB)\n",
      "Downloading Faker-27.4.0-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 466.4 kB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 466.4 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 524.3 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 524.3 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 524.3 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 524.3 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 524.3 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.3/1.8 MB 469.4 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.3/1.8 MB 469.4 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.3/1.8 MB 469.4 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 1.6/1.8 MB 487.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 541.9 kB/s eta 0:00:00\n",
      "Downloading json_repair-0.28.4-py3-none-any.whl (13 kB)\n",
      "Downloading structlog-25.1.0-py3-none-any.whl (68 kB)\n",
      "Downloading tiktoken-0.7.0-cp312-cp312-win_amd64.whl (799 kB)\n",
      "   ---------------------------------------- 0.0/799.3 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 262.1/799.3 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 524.3/799.3 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 799.3/799.3 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading oldest_supported_numpy-2023.12.21-py3-none-any.whl (4.9 kB)\n",
      "Downloading numpy-1.26.2-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/15.5 MB 1.2 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 1.0/15.5 MB 1.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.8/15.5 MB 2.2 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.4/15.5 MB 2.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.1/15.5 MB 2.6 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.9/15.5 MB 2.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.7/15.5 MB 2.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 5.8/15.5 MB 3.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 6.6/15.5 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.6/15.5 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 8.7/15.5 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 9.7/15.5 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.0/15.5 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.1/15.5 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading phonenumbers-8.13.54-py2.py3-none-any.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.8/2.6 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading pycryptodome-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading spacy-3.8.4-cp312-cp312-win_amd64.whl (11.8 MB)\n",
      "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.8 MB 4.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/11.8 MB 4.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.6/11.8 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.9/11.8 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.0/11.8 MB 4.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.3/11.8 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.6/11.8 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.9/11.8 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.0/11.8 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.8 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.8/11.8 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
      "Downloading unidiff-0.7.5-py2.py3-none-any.whl (14 kB)\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 632.6/632.6 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.4-cp312-cp312-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 0.8/1.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.2.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/6.3 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.6/6.3 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.3 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.3/5.4 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.4 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.4/5.4 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.7/5.4 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: fuzzysearch\n",
      "  Building wheel for fuzzysearch (setup.py): started\n",
      "  Building wheel for fuzzysearch (setup.py): finished with status 'done'\n",
      "  Created wheel for fuzzysearch: filename=fuzzysearch-0.7.3-py3-none-any.whl size=21246 sha256=c87e9fa0f8e0646d6bc0379f21426f72c57ac642af865af7561cf9999a3d80c8\n",
      "  Stored in directory: c:\\users\\pavansomisetty\\appdata\\local\\pip\\cache\\wheels\\08\\ee\\13\\5efaa9881e4a3f5d47c132c72c2383a05912d0b7e496e28afd\n",
      "Successfully built fuzzysearch\n",
      "Installing collected packages: unidiff, phonenumbers, cymem, wasabi, structlog, spacy-loggers, spacy-legacy, smart-open, shellingham, regex, pycryptodome, numpy, murmurhash, mdurl, marisa-trie, json-repair, fuzzysearch, cloudpathlib, catalogue, tiktoken, srsly, requests-file, presidio-anonymizer, preshed, oldest-supported-numpy, markdown-it-py, language-data, faker, blis, bc-detect-secrets, tldextract, rich, langcodes, confection, typer, thinc, weasel, spacy, presidio-analyzer, llm_guard\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.11.6\n",
      "    Uninstalling regex-2024.11.6:\n",
      "      Successfully uninstalled regex-2024.11.6\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.2\n",
      "    Uninstalling numpy-2.2.2:\n",
      "      Successfully uninstalled numpy-2.2.2\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.8.0\n",
      "    Uninstalling tiktoken-0.8.0:\n",
      "      Successfully uninstalled tiktoken-0.8.0\n",
      "Successfully installed bc-detect-secrets-1.5.15 blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.11 faker-27.4.0 fuzzysearch-0.7.3 json-repair-0.28.4 langcodes-3.5.0 language-data-1.3.0 llm_guard-0.3.15 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.12 numpy-1.26.2 oldest-supported-numpy-2023.12.21 phonenumbers-8.13.54 preshed-3.0.9 presidio-analyzer-2.2.354 presidio-anonymizer-2.2.354 pycryptodome-3.21.0 regex-2024.7.24 requests-file-2.1.0 rich-13.9.4 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 structlog-25.1.0 thinc-8.3.4 tiktoken-0.7.0 tldextract-5.1.3 typer-0.15.1 unidiff-0.7.5 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/markdown-it-py/\n"
     ]
    }
   ],
   "source": [
    "!pip install llm_guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07306fe8-479e-4134-8077-0bbca5209876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f43d28ca8f43ebbf118507253776cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7813f6970d48f5b0d9e3c3e12929d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697355b748e2498b94ba311db5ad39d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71904c508a4041fd952d5fb3dc03e6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b94e0027f14968a5ed19da6c12c929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ffa8b7cce548ba83ce3eddb9f19d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/882 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e5dfb4f79b4a829179c542b2897a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:29:20 [debug    ] Initialized classification model device=device(type='cpu') model=Model(path='MoritzLaurer/roberta-base-zeroshot-v2.0-c', subfolder='', revision='d825e740e0c59881cf0b0b1481ccf726b6d65341', onnx_path='protectai/MoritzLaurer-roberta-base-zeroshot-v2.0-c-onnx', onnx_revision='fde5343dbad32f1a5470890505c72ec656db6dbe', onnx_subfolder='', onnx_filename='model.onnx', kwargs={}, pipeline_kwargs={'batch_size': 1, 'device': device(type='cpu'), 'return_token_type_ids': False, 'max_length': 512, 'truncation': True}, tokenizer_kwargs={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from llm_guard.input_scanners import BanTopics\n",
    "scanner = BanTopics(topics=[\"violence\"], threshold=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ad09a-6130-4386-8267-a04b00a0d452",
   "metadata": {},
   "source": [
    "# with no banned topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d84c6ab4-8206-4a9f-844d-4032c2cff084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:37:34 [warning  ] Topics detected for the prompt scores={'violence': 0.022038791328668594}\n",
      "sanitized prompt: Hello, I hope you have a great day ahead!\n",
      "is valid: False\n",
      "risk score: 1.0\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hello, I hope you have a great day ahead!\"\n",
    "user_prompt, is_valid, risk_score = scanner.scan(prompt)\n",
    "print(f\"sanitized prompt: {user_prompt}\")\n",
    "print(f\"is valid: {is_valid}\")\n",
    "print(f\"risk score: {risk_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c006a-df11-4f90-a59c-13280a62fa60",
   "metadata": {},
   "source": [
    "#  Prompt with a banned topic (violence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c28cf63-29f8-4a19-a8f1-512d78ad5baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:38:20 [debug    ] Initialized classification model device=device(type='cpu') model=Model(path='MoritzLaurer/roberta-base-zeroshot-v2.0-c', subfolder='', revision='d825e740e0c59881cf0b0b1481ccf726b6d65341', onnx_path='protectai/MoritzLaurer-roberta-base-zeroshot-v2.0-c-onnx', onnx_revision='fde5343dbad32f1a5470890505c72ec656db6dbe', onnx_subfolder='', onnx_filename='model.onnx', kwargs={}, pipeline_kwargs={'batch_size': 1, 'device': device(type='cpu'), 'return_token_type_ids': False, 'max_length': 512, 'truncation': True}, tokenizer_kwargs={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:38:20 [warning  ] Topics detected for the prompt scores={'violence': 0.7936394810676575}\n",
      "sanitized prompt: I want to fight and hurt people!\n",
      "is valid: False\n",
      "risk score: 1.0\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I want to fight and hurt people!\"\n",
    "scanner = BanTopics(topics=[\"violence\"], threshold=0.0)\n",
    "user_prompt, is_valid, risk_score = scanner.scan(prompt)\n",
    "print(f\"sanitized prompt: {user_prompt}\")\n",
    "print(f\"is valid: {is_valid}\")\n",
    "print(f\"risk score: {risk_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac03548-a005-454b-8a76-bf026b9aaf7a",
   "metadata": {},
   "source": [
    "# Prompt with a banned topic (hate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12852a14-43d7-4141-ba73-72e0bb0c6a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:39:05 [debug    ] Initialized classification model device=device(type='cpu') model=Model(path='MoritzLaurer/roberta-base-zeroshot-v2.0-c', subfolder='', revision='d825e740e0c59881cf0b0b1481ccf726b6d65341', onnx_path='protectai/MoritzLaurer-roberta-base-zeroshot-v2.0-c-onnx', onnx_revision='fde5343dbad32f1a5470890505c72ec656db6dbe', onnx_subfolder='', onnx_filename='model.onnx', kwargs={}, pipeline_kwargs={'batch_size': 1, 'device': device(type='cpu'), 'return_token_type_ids': False, 'max_length': 512, 'truncation': True}, tokenizer_kwargs={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:39:05 [warning  ] Topics detected for the prompt scores={'hate': 0.9632165431976318}\n",
      "sanitized prompt: I hate everyone who disagrees with me.\n",
      "is valid: False\n",
      "risk score: 1.0\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I hate everyone who disagrees with me.\"\n",
    "scanner = BanTopics(topics=[\"hate\"], threshold=0.0)\n",
    "user_prompt, is_valid, risk_score = scanner.scan(prompt)\n",
    "print(f\"sanitized prompt: {user_prompt}\")\n",
    "print(f\"is valid: {is_valid}\")\n",
    "print(f\"risk score: {risk_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86250130-02a0-46f8-aae5-0ddf8fe716c0",
   "metadata": {},
   "source": [
    "# Prompt with a banned topic (drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bad0ee5-bd42-4508-a2f8-396db1b55779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:39:45 [debug    ] Initialized classification model device=device(type='cpu') model=Model(path='MoritzLaurer/roberta-base-zeroshot-v2.0-c', subfolder='', revision='d825e740e0c59881cf0b0b1481ccf726b6d65341', onnx_path='protectai/MoritzLaurer-roberta-base-zeroshot-v2.0-c-onnx', onnx_revision='fde5343dbad32f1a5470890505c72ec656db6dbe', onnx_subfolder='', onnx_filename='model.onnx', kwargs={}, pipeline_kwargs={'batch_size': 1, 'device': device(type='cpu'), 'return_token_type_ids': False, 'max_length': 512, 'truncation': True}, tokenizer_kwargs={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:39:45 [warning  ] Topics detected for the prompt scores={'drugs': 0.9602880477905273}\n",
      "sanitized prompt: Let's talk about how to make illegal drugs.\n",
      "is valid: False\n",
      "risk score: 1.0\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Let's talk about how to make illegal drugs.\"\n",
    "scanner = BanTopics(topics=[\"drugs\"], threshold=0.0)\n",
    "user_prompt, is_valid, risk_score = scanner.scan(prompt)\n",
    "print(f\"sanitized prompt: {user_prompt}\")\n",
    "print(f\"is valid: {is_valid}\")\n",
    "print(f\"risk score: {risk_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed4ee07-5450-48bb-a32b-940c85bf9a72",
   "metadata": {},
   "source": [
    "# Prompt with multiple banned topics (violence and hate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77dca2a8-e9c0-4d10-86bf-74d90a9669c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:40:28 [debug    ] Initialized classification model device=device(type='cpu') model=Model(path='MoritzLaurer/roberta-base-zeroshot-v2.0-c', subfolder='', revision='d825e740e0c59881cf0b0b1481ccf726b6d65341', onnx_path='protectai/MoritzLaurer-roberta-base-zeroshot-v2.0-c-onnx', onnx_revision='fde5343dbad32f1a5470890505c72ec656db6dbe', onnx_subfolder='', onnx_filename='model.onnx', kwargs={}, pipeline_kwargs={'batch_size': 1, 'device': device(type='cpu'), 'return_token_type_ids': False, 'max_length': 512, 'truncation': True}, tokenizer_kwargs={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:40:28 [warning  ] Topics detected for the prompt scores={'violence': 0.8224272131919861, 'hate': 0.17757278680801392}\n",
      "sanitized prompt: Violence is the answer to hatred.\n",
      "is valid: False\n",
      "risk score: 1.0\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Violence is the answer to hatred.\"\n",
    "scanner = BanTopics(topics=[\"violence\", \"hate\"], threshold=0.0)\n",
    "user_prompt, is_valid, risk_score = scanner.scan(prompt)\n",
    "print(f\"sanitized prompt: {user_prompt}\")\n",
    "print(f\"is valid: {is_valid}\")\n",
    "print(f\"risk score: {risk_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218509d-f515-4116-9f8b-0ff4c27eb7fb",
   "metadata": {},
   "source": [
    "# Prompt with a banned topic (violence) and a low threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "160a58a1-ed76-47bc-8b75-07544f8fe5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:41:16 [debug    ] Initialized classification model device=device(type='cpu') model=Model(path='MoritzLaurer/roberta-base-zeroshot-v2.0-c', subfolder='', revision='d825e740e0c59881cf0b0b1481ccf726b6d65341', onnx_path='protectai/MoritzLaurer-roberta-base-zeroshot-v2.0-c-onnx', onnx_revision='fde5343dbad32f1a5470890505c72ec656db6dbe', onnx_subfolder='', onnx_filename='model.onnx', kwargs={}, pipeline_kwargs={'batch_size': 1, 'device': device(type='cpu'), 'return_token_type_ids': False, 'max_length': 512, 'truncation': True}, tokenizer_kwargs={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:41:16 [debug    ] No banned topics detected      scores={'violence': 0.3700515031814575}\n",
      "sanitized prompt: I wish I could hurt someone.\n",
      "is valid: True\n",
      "risk score: 0.0\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I wish I could hurt someone.\"\n",
    "scanner = BanTopics(topics=[\"violence\"], threshold=0.5)\n",
    "user_prompt, is_valid, risk_score = scanner.scan(prompt)\n",
    "print(f\"sanitized prompt: {user_prompt}\")\n",
    "print(f\"is valid: {is_valid}\")\n",
    "print(f\"risk score: {risk_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67737d39-f72b-4531-a197-1905ec13a134",
   "metadata": {},
   "source": [
    "# Prompt with no banned topics but with a custom threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2dd6a45-4fc3-4a7f-ac30-067ca9876567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:42:12 [debug    ] Initialized classification model device=device(type='cpu') model=Model(path='MoritzLaurer/roberta-base-zeroshot-v2.0-c', subfolder='', revision='d825e740e0c59881cf0b0b1481ccf726b6d65341', onnx_path='protectai/MoritzLaurer-roberta-base-zeroshot-v2.0-c-onnx', onnx_revision='fde5343dbad32f1a5470890505c72ec656db6dbe', onnx_subfolder='', onnx_filename='model.onnx', kwargs={}, pipeline_kwargs={'batch_size': 1, 'device': device(type='cpu'), 'return_token_type_ids': False, 'max_length': 512, 'truncation': True}, tokenizer_kwargs={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:42:12 [debug    ] No banned topics detected      scores={'violence': 0.003345540724694729}\n",
      "sanitized prompt: Just another beautiful day in paradise!\n",
      "is valid: True\n",
      "risk score: 0.0\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Just another beautiful day in paradise!\"\n",
    "scanner = BanTopics(topics=[\"violence\"], threshold=0.5)\n",
    "user_prompt, is_valid, risk_score = scanner.scan(prompt)\n",
    "print(f\"sanitized prompt: {user_prompt}\")\n",
    "print(f\"is valid: {is_valid}\")\n",
    "print(f\"risk score: {risk_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1f198-3e85-459f-817d-8056a482838a",
   "metadata": {},
   "source": [
    "# other examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf3a109-4ef9-41a9-b36c-15458d1cd079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:30:17 [warning  ] Topics detected for the prompt scores={'violence': 0.017919858917593956}\n"
     ]
    }
   ],
   "source": [
    "prompt: str = \"Hello my name is pavan somisetty\"\n",
    "user_prompt, is_valid, risk_score = scanner.scan(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b53b0b-9b13-4cc8-ab39-34ff2d553674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanitized prompt: Hello my name is pavan somisetty\n",
      "is valid: False\n",
      "risk score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"sanitized prompt: {user_prompt}\")\n",
    "print(f\"is valid: {is_valid}\")\n",
    "print(f\"risk score: {risk_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8581c94-e8f0-41ef-acb6-5111bdcec1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:32:55 [warning  ] Topics detected for the prompt scores={'violence': 0.2674356698989868}\n",
      "sanitized prompt: How do I build a digital bomb?\n",
      "is valid: False\n",
      "risk score: 1.0\n"
     ]
    }
   ],
   "source": [
    "prompt: str = \"How do I build a digital bomb?\"\n",
    "user_prompt, is_valid, risk_score = scanner.scan(prompt)\n",
    "print(f\"sanitized prompt: {user_prompt}\")\n",
    "print(f\"is valid: {is_valid}\")\n",
    "print(f\"risk score: {risk_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1207376-96d4-4432-a45c-6da565a99946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:33:40 [debug    ] Initialized classification model device=device(type='cpu') model=Model(path='MoritzLaurer/roberta-base-zeroshot-v2.0-c', subfolder='', revision='d825e740e0c59881cf0b0b1481ccf726b6d65341', onnx_path='protectai/MoritzLaurer-roberta-base-zeroshot-v2.0-c-onnx', onnx_revision='fde5343dbad32f1a5470890505c72ec656db6dbe', onnx_subfolder='', onnx_filename='model.onnx', kwargs={}, pipeline_kwargs={'batch_size': 1, 'device': device(type='cpu'), 'return_token_type_ids': False, 'max_length': 512, 'truncation': True}, tokenizer_kwargs={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "scanner2 = BanTopics(topics=[\"violence\",\"threat\",\"illicit\"], threshold=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99486672-898d-477d-ab93-aa88c0c5a996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:34:37 [warning  ] Topics detected for the prompt scores={'threat': 0.42543840408325195, 'illicit': 0.3884667158126831, 'violence': 0.18609486520290375}\n",
      "sanitized prompt: How do I build a  digital bomb?\n",
      "is valid: False\n",
      "risk score: 1.0\n"
     ]
    }
   ],
   "source": [
    "prompt: str = \"How do I build a  digital bomb?\"\n",
    "user_prompt, is_valid, risk_score = scanner2.scan(prompt)\n",
    "print(f\"sanitized prompt: {user_prompt}\")\n",
    "print(f\"is valid: {is_valid}\")\n",
    "print(f\"risk score: {risk_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf5972-af80-469d-84ca-ab52475afc40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
